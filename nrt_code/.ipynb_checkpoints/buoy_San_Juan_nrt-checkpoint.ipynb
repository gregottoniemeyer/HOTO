{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc7cc-cfd5-4fbd-a39d-ec29b21e0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import xarray as xr\n",
    "import ephem\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from myconfig import *\n",
    "output_path = output_path_buoy_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe52d1-2e27-4b07-8835-c7df9d3b8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = '41043'\n",
    "fname = 'https://www.ndbc.noaa.gov/data/realtime2/'+station+'.txt'\n",
    "#more info: https://www.ndbc.noaa.gov/station_page.php?station=41043. 10 min intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306c390-3421-47ca-b7f0-f84c5f78c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buoy = pd.read_csv(fname, delim_whitespace=True, header=0, parse_dates=True,na_values='MM')\n",
    "#delete units row\n",
    "df_buoy = df_buoy.drop(index=0)\n",
    "df_buoy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5bb242-37fa-42c8-9927-6382070bbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match expected input for to_datetime\n",
    "df_buoy.rename(columns={\"#YY\": \"year\", \"MM\": \"month\", \"DD\": \"day\", \"hh\": \"hour\", \"mm\": \"minute\"}, inplace=True)\n",
    "\n",
    "# Combine the date and time columns into a single timestamp\n",
    "df_buoy['Timestamp'] = pd.to_datetime(df_buoy[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "df_clean_buoy = df_buoy.drop(columns=['year', 'month', 'day', 'hour', 'minute', 'DPD', 'MWD', 'PRES', 'DEWP', 'VIS', 'PTDY', 'TIDE']).drop(index=1)\n",
    "#df_clean_buoy.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a495c2-aaca-4ac9-88e8-e86ba19ab579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date and calculate the threshold for the last 7 days\n",
    "seven_days_ago = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Filter the DataFrame to only keep rows from the last 7 days\n",
    "df_last_7_days = df_clean_buoy[df_clean_buoy['Timestamp'] >= seven_days_ago]\n",
    "\n",
    "df_last_7_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57818ac1-e28a-4e79-ad18-6a47c61f0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse the data\n",
    "df_reversed_clean_buoy = df_last_7_days.iloc[::-1].reset_index(drop=True)\n",
    "#df_last_1800 = df_reversed_clean_buoy.tail(1800).copy()\n",
    "\n",
    "columns_to_convert = ['WDIR', 'WSPD', 'GST', 'WVHT', 'APD', 'ATMP', 'WTMP']\n",
    "\n",
    "# Convert specified columns to float, using 'coerce' to handle errors\n",
    "df_reversed_clean_buoy[columns_to_convert] = df_reversed_clean_buoy[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df_reversed_clean_buoy = df_reversed_clean_buoy.reset_index(drop=True)\n",
    "df_reversed_clean_buoy = df_reversed_clean_buoy.interpolate(method='linear', limit_direction='both')\n",
    "df_reversed_clean_buoy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db430b-60a8-4fa1-a829-f042feec1afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reversed_clean_buoy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a525dc1-721c-44e2-8de1-f0974764d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sunlight for each timestamp\n",
    "def calculate_sunlight(lat, lon, timestamps):\n",
    "    # Initialize observer\n",
    "    observer = ephem.Observer()\n",
    "    observer.lat = str(lat)\n",
    "    observer.lon = str(lon)\n",
    "\n",
    "    # Initialize the Sun object\n",
    "    sun = ephem.Sun()\n",
    "\n",
    "    # Store results\n",
    "    sunlight_data = []\n",
    "\n",
    "    for timestamp in timestamps:\n",
    "        observer.date = timestamp\n",
    "\n",
    "        # Compute the position of the sun for the observer at the given time\n",
    "        sun.compute(observer)\n",
    "\n",
    "        # Altitude is in degrees (-90 to 90), where 90 is zenith and 0 is on the horizon\n",
    "        altitude = sun.alt\n",
    "\n",
    "        # Normalize sunlight (1 for zenith, 0 for horizon, and negative for below horizon)\n",
    "        normalized_sunlight = max(0, altitude / ephem.degree)\n",
    "\n",
    "        sunlight_data.append(normalized_sunlight)\n",
    "\n",
    "    return pd.DataFrame({'timestamp': timestamps, 'sunlight_fraction': sunlight_data})\n",
    "\n",
    "# Latitude and longitude for the given location\n",
    "lat, lon =  19.71361111111111, -67.31083333333333\n",
    "\n",
    "timestamps = df_reversed_clean_buoy['Timestamp']\n",
    "\n",
    "# Calculate sunlight fraction for the entire time range\n",
    "sunlight_df = calculate_sunlight(lat, lon, timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddfdc7-ffd1-49b5-a15c-9b9dee7dedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reversed_clean_buoy[\"sun_exposure\"] = sunlight_df[\"sunlight_fraction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabb29f-dd2c-4939-991a-a211f4fbad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add glitter trough\n",
    "\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "# Define the function to generate the smooth symmetrical two peaks and trough normalized curve\n",
    "def generate_smooth_symmetric_two_peaks_trough_normalized(n):\n",
    "    key_positions = [0, 1, 5, 9, 10]  # Symmetrical positions with the trough in the center (at 5)\n",
    "    key_values = [0, 1, 0.33, 1, 0]  # Corresponding values for start, peaks, trough, and end\n",
    "    \n",
    "    # Use cubic spline for smooth interpolation\n",
    "    spline_interpolator = CubicSpline(key_positions, key_values, bc_type=((1, 0), (1, 0)))\n",
    "\n",
    "    # Generate evenly spaced positions for n steps\n",
    "    new_positions = np.linspace(0, 10, n)\n",
    "\n",
    "    # Generate interpolated values with the cubic spline\n",
    "    smooth_values = spline_interpolator(new_positions)\n",
    "\n",
    "    # Normalize the result to range 0-1\n",
    "    normalized_values = (smooth_values - smooth_values.min()) / (smooth_values.max() - smooth_values.min())\n",
    "\n",
    "    return pd.DataFrame(normalized_values, columns=['Normalized Symmetrical Two Peaks and Trough'])\n",
    "\n",
    "# Function to apply the spline curve to an interval\n",
    "def apply_spline_to_interval(df, start, end):\n",
    "    n = end - start + 1\n",
    "    print(end,start,n)\n",
    "    # Generate the smooth curve\n",
    "    spline_df = generate_smooth_symmetric_two_peaks_trough_normalized(n)\n",
    "    \n",
    "    # Multiply sun exposure in the interval by the spline values\n",
    "    df.loc[start:end, 'sun_exposure_modified'] = df.loc[start:end, 'sun_exposure'] * spline_df.values.flatten()\n",
    "\n",
    "# Add a shifted column to detect changes in sun exposure\n",
    "df_reversed_clean_buoy['sun_exposure_shift'] = df_reversed_clean_buoy['sun_exposure'].shift(1)\n",
    "\n",
    "# Find the start and end of intervals where sun exposure transitions from 0 to >0 and back to 0\n",
    "start_intervals = df_reversed_clean_buoy[(df_reversed_clean_buoy['sun_exposure_shift'] == 0) & (df_reversed_clean_buoy['sun_exposure'] > 0)].index\n",
    "end_intervals = df_reversed_clean_buoy[(df_reversed_clean_buoy['sun_exposure_shift'] > 0) & (df_reversed_clean_buoy['sun_exposure'] == 0)].index\n",
    "\n",
    "print(start_intervals)\n",
    "print(end_intervals)\n",
    "print('***** GREG CHECK *** reversed start/end below')\n",
    "\n",
    "# Pair up the start and end intervals\n",
    "#intervals = list(zip(start_intervals, end_intervals))\n",
    "intervals = list(zip(end_intervals, start_intervals))\n",
    "\n",
    "# Apply the spline modification to all intervals\n",
    "for start, end in intervals:\n",
    "    apply_spline_to_interval(df_reversed_clean_buoy, start, end)\n",
    "\n",
    "df_reversed_clean_buoy['sun_exposure_modified'].fillna(0.0, inplace=True)\n",
    "df_reversed_clean_buoy['sun_exposure_shift']=df_reversed_clean_buoy.sun_exposure_shift[1]\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "df_reversed_clean_buoy.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7fe7f-ea1e-4348-8978-649e5389b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_reversed_clean_buoy.sun_exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083f72f-b122-4634-8de9-c25a5b597c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = np.linspace(0, len(df_reversed_clean_buoy) - 1, 7200)\n",
    "\n",
    "df = df_reversed_clean_buoy\n",
    "df_interpolated = pd.DataFrame()\n",
    "for var in df.columns:\n",
    "    if var=='Timestamp':\n",
    "        continue\n",
    "    df_interpolated[var] = np.interp(new_index, np.arange(len(df)), df[var])\n",
    "# Interpolate 'timestamp' column onto the new index (if you want to interpolate timestamps too)\n",
    "df_interpolated['Timestamp'] = pd.to_datetime(np.interp(new_index, np.arange(len(df)), df['Timestamp'].astype(int)))\n",
    "df_interpolated['Timestamp'] = pd.to_datetime(df_interpolated['Timestamp'])\n",
    "#print(df_interpolated.sun_exposure[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea8c96-aab3-4796-9241-585d4d051365",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_interpolated.sun_exposure)\n",
    "#df_expanded.sun_exposure[60:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f011c-afcb-4316-8d3c-ad46cca8b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize and park\n",
    "# Assuming 'df' is already loaded and has the 'Sample' column\n",
    "# Normalize the 'Sample' column using min-max normalization\n",
    "df = df_interpolated\n",
    "vars = ['WDIR','WSPD','GST','WVHT','APD','ATMP','WTMP']\n",
    "df_normalized = df\n",
    "for var in vars:\n",
    "    df_normalized[var] = (df[var] - np.min(df[var])) / (np.max(df[var]) - np.min(df[var]))\n",
    "# Display the resulting DataFrame (showing first and last 10 rows)\n",
    "df_normalized.head(3), df_normalized.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19bb67-5760-4eb9-b90b-b08bdbddb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['Timestamp','WDIR', 'WSPD', 'GST', 'WVHT', 'APD', 'ATMP', 'WTMP', \n",
    "       'sun_exposure', 'sun_exposure_shift', 'sun_exposure_modified']\n",
    "new_df = df_normalized[new_order]\n",
    "fname = output_path + 'buoy_nrt.csv'\n",
    "new_df.to_csv(fname, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef152045-3822-457f-a464-4b6e33741fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(new_df.sun_exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538050b1-b849-44e5-9c13-48f0741040dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
